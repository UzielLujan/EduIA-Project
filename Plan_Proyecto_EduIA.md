# Plan ‚ÄúEduIA‚Äù ‚Äì Educador Multimodal Inteligente Acad√©mico

## üéØ Objetivo

Desarrollar un sistema que reciba texto como pregunta y devuelva:

- **Explicaci√≥n generativa en espa√±ol.**
- **Imagen de apoyo visual** (diagrama, gr√°fico o ilustraci√≥n simple).

Todo tratando de usar modelos open source y t√©cnicas aprendidas en el curso.

---

## 1Ô∏è‚É£ Arquitectura general

```
Pregunta ‚Üí Preprocesamiento ‚Üí Modelo de texto (QA generativo)
       ‚Üò                           ‚Üô
        Generador de imagen (Stable Diffusion / program√°tico)
                    ‚Üì
       Respuesta final (texto + imagen)
```

---

## 2Ô∏è‚É£ Componentes y tecnolog√≠as

### M√≥dulo de Texto

- **Base:** Experimentar con 2 modelos y evaluarlos, FLAN-T5-XL y BLOOMZ-3B (HuggingFace) ‚Äì modelos multiling√ºes con buen rendimiento en espa√±ol.

- **Estrategia:**

    - Prompt engineering para forzarlos a devolver el formato: explicaci√≥n clara + descripci√≥n breve y concreta de la sugerencia visual o imagen de apoyo.
    - Fine-tuning ligero opcional con dataset educativo en espa√±ol (ej. adaptaci√≥n de SQuAD-es o conjunto propio).
- **Framework:** Transformers de HuggingFace + PyTorch.

### M√≥dulo de Imagen

- **Opci√≥n 1 (generativa):** Stable Diffusion ejecutado localmente con pesos open source, evitando el uso de servicios de pago ‚Üí genera diagramas o ilustraciones simples seg√∫n descripci√≥n.
- **Opci√≥n 2 (program√°tica):** Matplotlib, NetworkX, Graphviz, o Mermaid ‚Üí genera gr√°ficos, diagramas de flujo, o esquemas autom√°ticos a partir de datos estructurados.

- **Decisi√≥n din√°mica:**
    - Si el tema es m√°s abstracto (ej. ‚Äúred neuronal‚Äù), usar Stable Diffusion.
    - Si es t√©cnico-matem√°tico, usar imagen program√°tica.

---

## Integraci√≥n

Script Python que:

1. Recibe pregunta.
2. Llama al modelo de texto para generar explicaci√≥n y descripci√≥n de imagen.
3. Llama al generador de im√°genes con esa descripci√≥n.
4. Devuelve ambos como respuesta integrada.

---

## 3Ô∏è‚É£ Flujo detallado

**1. Entrada:** Texto de pregunta.

**2. Preprocesamiento:**
    - Limpieza m√≠nima (caracteres mal formateados).

**3. Modelo de texto:**

Prompt base:
```text
Responde a la siguiente pregunta de forma clara y detallada. Incluye tambi√©n una breve descripci√≥n de un diagrama o imagen que ayudar√≠a a entender la respuesta. Pregunta: {input}
```

**4. Postprocesamiento texto:**
- Separar la parte de explicaci√≥n y la descripci√≥n de la imagen.

**5. Generaci√≥n de imagen:**
- Stable Diffusion: usar descripci√≥n para crear ilustraci√≥n.
- Program√°tico: traducir descripci√≥n a c√≥digo de diagrama.

**6. Salida combinada:**
- Mostrar explicaci√≥n y renderizar imagen en interfaz web.




---

## 4Ô∏è‚É£ Extras para impresionar

- Explicaciones paso a paso: forzar modelo a numerar pasos.
- Interfaz web: Gradio o Streamlit para que cualquiera pruebe el prototipo.
- M√©trica de evaluaci√≥n: BLEU/ROUGE para medir calidad textual y un score de similaridad CLIP para evaluar relevancia imagen‚Äìtexto.

---

## 5Ô∏è‚É£ Recursos recomendados

- HuggingFace Transformers para modelos NLP.
- Diffusers para Stable Diffusion local.
- Matplotlib / Graphviz para diagramas program√°ticos.
- **Datasets:**
- SQuAD-es, MLQA-es para QA.
- Colecciones propias para ejemplos visuales.



## üì° Estrategia de Ejecuci√≥n en Cl√∫ster ‚Äì Flujo ‚ÄúBatch‚Äù Acad√©mico

Dado que el cl√∫ster Lab-SB (CIMAT) no est√° dise√±ado para servir interfaces web en tiempo real, el flujo de ejecuci√≥n de *EduIA* se adaptar√° a un esquema **batch**. Esto permite aprovechar la potencia del superc√≥mputo para generar todas las salidas (texto + im√°genes) de forma masiva y luego presentarlas localmente simulando tiempo real.

### üîπ Descripci√≥n del flujo

1. **Preparaci√≥n local**
   - Descargar y almacenar modelos, tokenizers y datasets de HuggingFace en local.
   - Transferir al cl√∫ster mediante SFTP (`scp` o Bitvise) siguiendo la estructura:
     ```
     /EduIA/
     ‚îú‚îÄ‚îÄ models/         # Modelos locales (FLAN-T5-XL, BLOOMZ-3B)
     ‚îú‚îÄ‚îÄ data/           # Preguntas y prompts
     ‚îî‚îÄ‚îÄ scripts/        # C√≥digo fuente + .sh de lanzamiento
     ```
   
2. **Ejecuci√≥n en el cl√∫ster (SLURM)**
   - Usar scripts `.sh` con configuraci√≥n de SLURM para lanzar la generaci√≥n en modo batch.
   - Los scripts recibir√°n como entrada:
     - Ruta del modelo base.
     - Archivo de preguntas.
     - Directorio de salida.
   - El cl√∫ster procesar√° todas las preguntas, generando:
     - `resultados.json` ‚Üí texto explicativo y descripci√≥n visual.
     - Carpeta `imagenes/` ‚Üí im√°genes generadas (Stable Diffusion o program√°ticas).
   
3. **Postprocesamiento y transferencia**
   - Descargar resultados (`resultados.json` + `imagenes/`) a la m√°quina local.
   - Guardar en `/EduIA/results/` para que la interfaz web pueda acceder a ellos.

4. **Visualizaci√≥n local**
   - La interfaz web (Gradio o Streamlit) leer√° los resultados pre-generados y los mostrar√° como si fueran respuestas en tiempo real.
   - Posible opci√≥n de ‚Äúreprocesar‚Äù una pregunta envi√°ndola a una cola batch en el cl√∫ster para ejecuci√≥n posterior.

### üîπ Ventajas del enfoque
- Aprovecha el cl√∫ster para la parte m√°s costosa: generaci√≥n de texto e imagen.
- Evita latencias y cuellos de botella propios del tiempo real.
- Mantiene el car√°cter acad√©mico y reproducible del proyecto.
- Permite demos fluidas sin depender de la conexi√≥n al HPC.

### üîπ Notas importantes
- Los modelos y datasets deben subirse completos al cl√∫ster (no hay internet en nodos de c√≥mputo).
- La carpeta `logs/` ser√° clave para depuraci√≥n y trazabilidad de resultados.
- Mantener scripts `.sh` en la ra√≠z del proyecto para simplificar rutas.
